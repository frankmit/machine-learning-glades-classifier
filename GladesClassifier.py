"""
TITLE:          GladesClassifier.py
DESCRIPTION:    GLADES - a random forest algorithm in python
AUTHOR:         Frank Lo


README:

--------------------------
NOTES AND CONTACT
--------------------------
This is not the fastest random forest algorithm out there, nor the most feature-packed, but it works well and is meant to be an implementation of random forest in python that is very intuitive to use. The original motivation for writing my own version of the algorithm from the ground up was wanting forest and tree objects to be easier to view and dissect, represented in a transparent and easy-to-parse format.

RandomForestClassifier in scikit-learn generates tree objects that are somewhat opaque in the sense that you cannot 'print' those objects directly, rather they must be parsed through a very specific process to create a visual representation of the tree. It involves more messy hacking than I prefer; I'd rather to view trees in a simpler, more raw format.

GladesClassifier (this library) focuses on making forests and trees easier to work with. Trees are represented as nested dicts, with easily viewable and parsable information at each node. Forests are represented as lists of trees.
Reading the contents of forest is as simple as writing a statement such as: print my_forest_name
Reading the contents of a tree within a forest (in this case the first tree): print my_forest_name[0]

Any questions, email me: franklo@alum.mit.edu


--------------------------
PARAMETER DETAILS: grow_a_forest
--------------------------

df:
Pandas dataframe with input data - includes dependent variable and all independent variables as columns.

feature_space:
List of names of independent variables in data to be considered in forest. E.g.
feature_space = ["x1","x2","x3"]

target_var:
Name of dependent variable in data

target_value:
Value to look for in target_var to indicate success.
E.g. if target_var is a binary variable (0 or 1), then target_value would be 1

tree count:
Number of trees to grow in the forest

bootstrap_size:
For each tree, approximately what size subset of data should be taken for each bootstrap sample

subspace_size:
For each tree, the number of features that should be randomly selected from the feature_space to form a subspace for the table

slices:
At each node, every feature is scanned through from its min to max, looking for an optimal cut. In order to do this, the algorithm iterates through 'slices' of data from min to max. This slices setting indicates the number of cuts to iterate through. Higher means more granular, but slower.
E.g. if a feature X has range 0-100, and slices=100, then algorithm will consider branching at X at 1,2,3 ... 97,98,99. If slices it set to 1000, , then algorithm will consider branching at X at 0.1,0.2,0.3 ... 0.97,0.98,0.99.
Default value is 100

minimum_slice_points:
At each slice, algorithm will consider branching, or skip to next slice if not enough points exist. minimum_slice_points indicates the minimum number of points needed to consider branching.
E.g. if minimum_slice_points=20, then if a slice has less than 20 points either above or below, it is forced to be terminated as a leaf. Otherwise, it is possible to split to deeper nodes..
Default value is 20

tree_depth:
Maximum depth that a tree can reach. Higher depth means more complex trees. Default value is 3.

return value:
a list of trees, representing the forest. Each tree is a dict with nested dicts to indicate nodes.


--------------------------
PARAMETER DETAILS: score_aggregation
--------------------------

df:
Pandas dataframe, with variable names corresponding to the variables in the forest.

forest: 
A forest that was generated by grow_a_forest.

return value:
A copy of df, but appended with a variables "target_score" and "rank", representing scores and selection rank for each observation.


--------------------------
PARAMETER DETAILS: create_probability_map
--------------------------

df:
Pandas dataframe, representing a scored dataset, returned by score_aggregation()

target_var:
Name of dependent variable in data

target_value:
Value to look for in target_var to indicate success.

ntiles:
Specifies granularity of probability map that is returned. E.g. if ntile=100, then every centile is assigned its own probability; if ntile=10, then every decile is assigned its own probability.

return value:
A dataframe representing a mapping between score calculated by forest with score_aggregation(), and target probability


--------------------------
EXAMPLE CODE
--------------------------

# grow a forest
tree_record = grow_a_forest(df=df_training,
                              feature_space=["x","y"],
                              target_var="actual_class",
                              target_value="Premium",
                              tree_count=50,
                              bootstrap_size=150,
                              subspace_size=2,
                              slices=100,
                              minimum_slice_points=20,                              
                              tree_depth=3
                              )

# run data through the forest
df_validation_scored = score_aggregation(df=df_validation, forest=tree_record)

# map scores to probabilities
probability_map = create_probability_map(df_validation_scored, target_var="actual_class", target_value="Premium", ntiles=100)
"""

import pandas as pd
import numpy as np

################## BUILD A RANDOM TREE

##### FIND DECISION THRESHOLD AND GROW BRANCH
def fork_tree(data, subspace_list, target_var, target_value, slices, minimum_slice_points, tree_depth, branch_depth):    
    #create empty dataframe to store slice results
    slice_columns = ["subspace","slice_value","below_class","below_count","below_misclass_count","below_target_prob","above_class","above_count","above_misclass_count","above_target_prob","total_misclass_count"]
    slice_record = pd.DataFrame(columns=slice_columns)
    
    ##### GREEDY METHOD
    for subspace in subspace_list:
    
        for slice_counter in xrange(slices):
            
            spread = data[subspace].max() - data[subspace].min()
            slice_value = spread/slices * slice_counter + data[subspace].min()
            
            points_below = data[data[subspace] < slice_value]
            points_above = data[data[subspace] >= slice_value]
        
            # determine side with highest target saturation
            below_target_count = points_below[points_below[target_var] == target_value].shape[0]
            below_nontarget_count = points_below[points_below[target_var] != target_value].shape[0]
            above_target_count = points_above[points_above[target_var] == target_value].shape[0]
            above_nontarget_count = points_above[points_above[target_var] != target_value].shape[0]    
                
            below_total_count = below_target_count + below_nontarget_count
            above_total_count = above_target_count + above_nontarget_count
            
            if below_total_count <= minimum_slice_points or above_total_count <= minimum_slice_points:
                continue    #not enough points, skip to the next iteration
            
            below_target_prob = below_target_count/below_total_count
            above_target_prob = above_target_count/above_total_count
        
            if below_target_prob > above_target_prob:
                below_class_assignment = "target"
                above_class_assignment = "nontarget"
                
                below_misclassification_count = below_nontarget_count
                above_misclassification_count = above_target_count
                
            elif below_target_prob < above_target_prob:
                below_class_assignment = "nontarget"
                above_class_assignment = "target"
                
                below_misclassification_count = below_target_count
                above_misclassification_count = above_nontarget_count
                
            else:
                below_class_assignment = "tie"
                above_class_assignment = "tie"
                
                below_misclassification_count = below_target_count
                above_misclassification_count = above_target_count
        
            #squared error, which in this case is same as misclassification count (because 1**2 == 1)
            total_misclassification_count = below_misclassification_count + above_misclassification_count
        
            # store results in slice_record dataframe
            new_slice = pd.DataFrame(
                [[subspace,slice_value,
                     below_class_assignment, below_total_count, below_misclassification_count, below_target_prob,
                     above_class_assignment, above_total_count, above_misclassification_count, above_target_prob,
                     total_misclassification_count]],   #coerce into creating a new row of data
                columns=slice_columns)
            slice_record = pd.concat([slice_record, new_slice], ignore_index=True)
            #print(slice_record.to_string())
    
    # check if slice_record is blank (not enough data points to branch)
    if slice_record.shape[0] == 0:
        target_count = data[data[target_var] == target_value].shape[0]
        nontarget_count = data[data[target_var] != target_value].shape[0]          
        total_count = target_count + nontarget_count
        target_prob = target_count/total_count
        return target_prob   #return overall probability for this division
    
    ##### MINIMIZE MISCLASSIFICATION ERROR
    # find row(s) with the minimum misclassification
    lowest_misclassification_count = slice_record.total_misclass_count.min()
    slice_record_minimized = slice_record[slice_record.total_misclass_count == lowest_misclassification_count]
    
    # in case multiple rows exist, pick one at random
    slice_record_minimized_rows = slice_record_minimized.shape[0]
    slice_record_minimized_randrow = np.random.randint(0, slice_record_minimized_rows)
    slice_record_minimized_randrow_index = slice_record_minimized.index[slice_record_minimized_randrow]
    slice_record_minimized = slice_record_minimized[slice_record_minimized.index == slice_record_minimized_randrow_index]
    #print(slice_record_minimized.to_string())
    
    ##### RECURSE OR END RECURSION
    # this is the decision threshold for this node in the tree
    optimal_slice_value = slice_record_minimized.slice_value[slice_record_minimized_randrow_index]
    optimal_subspace = slice_record_minimized.subspace[slice_record_minimized_randrow_index]
    
    #check to see if we've reached the maximum depth of the tree
    if branch_depth < tree_depth:
        # if no, fork the tree
        below_output = fork_tree(data[data[optimal_subspace] < optimal_slice_value], subspace_list, target_var, target_value, slices, minimum_slice_points, tree_depth, branch_depth + 1)
        above_output = fork_tree(data[data[optimal_subspace] >= optimal_slice_value], subspace_list, target_var, target_value, slices, minimum_slice_points, tree_depth, branch_depth + 1)
    else:
        # if yes, pull the probabilities
        below_output = slice_record_minimized.below_target_prob[slice_record_minimized_randrow_index]
        above_output = slice_record_minimized.above_target_prob[slice_record_minimized_randrow_index]

    ##### PUT TREE INTO NESTED DICT FORMAT
    tree = {"subspace" : optimal_subspace,
            "threshold" : optimal_slice_value,
            "below" : below_output,
            "above" : above_output}
    return tree
    


##### CREATE A BOOTSTRAP AND RANDOM SUBSPACE; BUILD A TREE

def grow_random_tree(df, feature_space, target_var, target_value, bootstrap_size, subspace_size, slices, minimum_slice_points, tree_depth):
    ##### BOOTSTRAP SAMPLE
    bootstrap_sample = df[df.index.isin(np.random.choice(df.shape[0], bootstrap_size, replace=False))]
    
    ##### RANDOM SUBSPACES
    random_subspace = []
    random_subspace_index = np.random.choice(len(feature_space), subspace_size, replace=False)
    for i in random_subspace_index:
        random_subspace.append(feature_space[i])
    
    ##### START A NEW TREE
    print "subspace:",random_subspace
    return fork_tree(bootstrap_sample, random_subspace, target_var, target_value, slices, minimum_slice_points, tree_depth, 1)



################## BUILD ALL RANDOM TREES

def grow_a_forest(df, feature_space, target_var, target_value, tree_count, bootstrap_size, subspace_size, slices=100, minimum_slice_points=20, tree_depth=3):
    for tree_counter in xrange(tree_count):
        if tree_counter == 0:
            # initiate tree_record table
            tree_record = [grow_random_tree(df, feature_space, target_var, target_value, bootstrap_size, subspace_size, slices, minimum_slice_points, tree_depth)]
        else:
            tree_record.append(grow_random_tree(df, feature_space, target_var, target_value, bootstrap_size, subspace_size, slices, minimum_slice_points, tree_depth))
        
        print "tree", tree_counter+1, "of", tree_count, "--", tree_record[tree_counter]
        
    return tree_record
        
        

################## SCORE DATA WITH FOREST

##### RECURSIVELY FOLLOW TREE
def follow_tree(current_tree, df, current_datapoint):
    current_subspace = current_tree["subspace"]
    current_threshold = current_tree["threshold"]

    # which side of the decision threshold is the data
    if df[current_subspace][current_datapoint] < current_threshold:
        
        # is the node the final probability or another tree; recurse if another tree
        if type(current_tree["below"]) != dict:
            return current_tree["below"]
        else:
            subtree = current_tree["below"]
            return follow_tree(subtree, df, current_datapoint)  #recurse
    else:
        if type(current_tree["above"]) != dict:
            return current_tree["above"]
        else:
            subtree = current_tree["above"]
            return follow_tree(subtree, df, current_datapoint)  #recurse



##### LEAF SCORE AGGREGRATION
def score_aggregation(df, forest):
    df_scored = df
    df_scored["target_score"] = np.NaN
    
    total_datapoints = df.shape[0]
    tree_count = len(forest)
    datapoint_counter = 0
    
    # loop through all the points
    for datapoint_i in df.index:
        
        # sum of scores from all the trees; initiate
        target_score_sum = 0
        
        # loop through the trees
        for tree_counter in xrange(tree_count):       
            target_score_sum += follow_tree(forest[tree_counter], df, datapoint_i)
            
        df_scored.target_score[datapoint_i] = target_score_sum/tree_count
        
        if datapoint_counter % 200 == 0:
            print "% complete:", np.round(datapoint_counter/total_datapoints * 100, 1)
        
        datapoint_counter += 1
    
    print "% complete: 100.0"
    
    df["rank"] = df.target_score.rank(method="first", ascending=False)
    return df_scored



##### ESTIMATE PROBABILITIES FROM SCORE
# Summary: Estimate the probability of an observation belonging to class, based on localized target rates within the ntile in which a observation falls

# General Method: Determine an ntile for every observation, based on the score output of the random forest. Then map each observation to a probability based on its ntile.

# E.g., A score between .5 and .6 may represent a top ntile based on the forest prediction. This ntile has a 90% target rate in actual data; thus the target probability of observations within this score range is 90%
 
def create_probability_map(df, target_var, target_value, ntiles=250):

    total_points = df.shape[0]
    count_per_ntile = total_points/ntiles
    
    df_ntile = pd.DataFrame(range(ntiles), columns=["ntile"])
    
    df_ntile["rank_min"] = df_ntile["ntile"] * count_per_ntile
    df_ntile["rank_max"] = (df_ntile["ntile"] + 1) * count_per_ntile
    
    df_ntile["score_min"] = np.NaN
    df_ntile["score_max"] = np.NaN
    df_ntile["target_probability"] = np.NaN
    
    for ntile_number in range(ntiles):
        rank_min = df_ntile.rank_min[ntile_number]
        rank_max = df_ntile.rank_max[ntile_number]
        
        df_subset = df[(df["rank"] >= rank_min) & (df["rank"] < rank_max)]
        
        df_ntile.score_min[ntile_number] = df_subset["target_score"].min()
        df_ntile.score_max[ntile_number] = df_subset["target_score"].max()
        df_ntile.target_probability[ntile_number] = np.where(df_subset[target_var] == target_value, 1, 0).sum() / count_per_ntile
    
    # if target_score is higher, use that as the probability to smooth ripples; this is ok because target_score is meant to be a probability anyway (but can be underestimated if trees are not deep enough)
    probability_adjust_records = df_ntile.score_max > df_ntile.target_probability
    df_ntile.target_probability[probability_adjust_records] = df_ntile.score_max[probability_adjust_records]    
    
    return df_ntile