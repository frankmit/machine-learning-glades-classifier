TITLE:          GladesClassifier
DESCRIPTION:    GLADES - A Random Forest algorithm in Python, with JSON representations of forests
AUTHOR:         Frank Lo (franklo@alum.mit.edu)

--------------------------
NOTES AND CONTACT
--------------------------
This is not the fastest random forest algorithm out there, nor the most feature-packed, but it works well and is meant to be an implementation of random forest in python that is very intuitive to use. The original motivation for writing my own version of the algorithm from the ground up was wanting forest and tree objects to be easier to view and dissect, represented in a transparent, human-readable, easy-to-parse manner -- JSON format.

RandomForestClassifier in scikit-learn generates tree objects that are somewhat opaque in the sense that you cannot 'print' those objects directly, rather they must be parsed through a very specific process to create a visual representation of the tree. It involves more messy hacking than I prefer; I'd rather to view trees in a simpler, more raw format.

GladesClassifier (this library) focuses on making forests and trees easier to work with by representing the forest in JSON format. Individual trees within forests, and nodes within trees, are all easily viewable and parsable. Another way to read it is that trees represented as nested dicts, and a forest is represented as a list of trees. The hierarchical structure of trees and forests fits into the JSON construct perfectly.

Reading the contents of forest is as simple as writing a statement such as: print my_forest_name
Reading the contents of a tree within a forest (in this case the first tree): print my_forest_name[0]

Any questions, email me: franklo@alum.mit.edu


--------------------------
PARAMETER DETAILS: grow_a_forest
--------------------------

df:
Pandas dataframe with input data - includes dependent variable and all independent variables as columns.

feature_space:
List of names of independent variables in data to be considered in forest. E.g.
feature_space = ["x1","x2","x3"]

target_var:
Name of dependent variable in data

target_value:
Value to look for in target_var to indicate success.
E.g. if target_var is a binary variable (0 or 1), then target_value would be 1

tree count:
Number of trees to grow in the forest

bootstrap_size:
For each tree, approximately what size subset of data should be taken for each bootstrap sample

subspace_size:
For each tree, the number of features that should be randomly selected from the feature_space to form a subspace for the table

slices:
At each node, every feature is scanned through from its min to max, looking for an optimal cut. In order to do this, the algorithm iterates through 'slices' of data from min to max. This slices setting indicates the number of cuts to iterate through. Higher means more granular, but slower.
E.g. if a feature X has range 0-100, and slices=100, then algorithm will consider branching at X at 1,2,3 ... 97,98,99. If slices it set to 1000, , then algorithm will consider branching at X at 0.1,0.2,0.3 ... 0.97,0.98,0.99.
Default value is 100

minimum_slice_points:
At each slice, algorithm will consider branching, or skip to next slice if not enough points exist. minimum_slice_points indicates the minimum number of points needed to consider branching.
E.g. if minimum_slice_points=20, then if a slice has less than 20 points either above or below, it is forced to be terminated as a leaf. Otherwise, it is possible to split to deeper nodes..
Default value is 20

tree_depth:
Maximum depth that a tree can reach. Higher depth means more complex trees. Default value is 3.

return value:
a list of trees, representing the forest. Each tree is a dict with nested dicts to indicate nodes.


--------------------------
PARAMETER DETAILS: save_forest_as_json
--------------------------

forest: 
A forest that was generated by grow_a_forest.

json_filename:
filename (with .json extension) used to save the forest. Will be saved in your current working directory.


--------------------------
PARAMETER DETAILS: load_forest_json
--------------------------

json_filename:
filename (with .json extension) of saved forest to load to python environment. Will load from your current working directory.

return value:
A forest, loaded from JSON file


--------------------------
PARAMETER DETAILS: score_aggregation
--------------------------

df:
Pandas dataframe, with variable names corresponding to the variables in the forest.

forest: 
A forest that was generated by grow_a_forest.

return value:
A copy of df, but appended with a variables "target_score" and "rank", representing scores and selection rank for each observation.


--------------------------
PARAMETER DETAILS: create_probability_map
--------------------------

df:
Pandas dataframe, representing a scored dataset, returned by score_aggregation()

target_var:
Name of dependent variable in data

target_value:
Value to look for in target_var to indicate success.

ntiles:
Specifies granularity of probability map that is returned. E.g. if ntile=100, then every centile is assigned its own probability; if ntile=10, then every decile is assigned its own probability.

return value:
A dataframe representing a mapping between score calculated by forest with score_aggregation(), and target probability


--------------------------
EXAMPLE CODE
--------------------------

# grow a forest
tree_record = grow_a_forest(df=df_training,
                              feature_space=["x","y"],
                              target_var="actual_class",
                              target_value="Premium",
                              tree_count=50,
                              bootstrap_size=150,
                              subspace_size=2,
                              slices=100,
                              minimum_slice_points=20,                              
                              tree_depth=3
                              )


# save forest to JSON
save_forest_as_json(tree_record, "my_forest.json")

# load forest from JSON
tree_record = load_forest_json("my_forest.json")


# run data through the forest
df_validation_scored = score_aggregation(df=df_validation, forest=tree_record)

# map scores to probabilities
probability_map = create_probability_map(df_validation_scored, target_var="actual_class", target_value="Premium", ntiles=100)
